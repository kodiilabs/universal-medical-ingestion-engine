{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Extraction Test\n",
    "\n",
    "This notebook tests what the API returns when processing a document file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "API_BASE = 'http://localhost:8000'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check API Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(f'{API_BASE}/api/health')\n",
    "print(f'Status: {response.status_code}')\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. List Available Sample Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(f'{API_BASE}/api/samples')\n",
    "samples = response.json()\n",
    "print(f'Found {len(samples)} sample files:')\n",
    "for sample in samples[:10]:\n",
    "    print(f\"  - {sample.get('path', sample)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Process a Sample Document via API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process LabCorp sample\n",
    "file_path = 'data/samples/labs/labcorp/SampleLabCorpReport.pdf'\n",
    "\n",
    "response = requests.post(\n",
    "    f'{API_BASE}/api/v2/samples/process',\n",
    "    params={'file_path': file_path, 'strategy': 'router'}\n",
    ")\n",
    "\n",
    "job_data = response.json()\n",
    "job_id = job_data.get('job_id')\n",
    "print(f'Job ID: {job_id}')\n",
    "print(f'Status: {job_data.get(\"status\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poll for completion\n",
    "def wait_for_job(job_id, timeout=300):\n",
    "    start = time.time()\n",
    "    while time.time() - start < timeout:\n",
    "        response = requests.get(f'{API_BASE}/api/v2/jobs/{job_id}')\n",
    "        data = response.json()\n",
    "        status = data.get('status')\n",
    "        print(f'Status: {status}')\n",
    "        if status in ['completed', 'failed']:\n",
    "            return data\n",
    "        time.sleep(5)\n",
    "    return None\n",
    "\n",
    "result = wait_for_job(job_id)\n",
    "print(f'\\nFinal status: {result.get(\"status\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inspect the Full API Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top-level keys\n",
    "print('Top-level keys:', list(result.keys()))\n",
    "\n",
    "# Show result keys\n",
    "if result.get('result'):\n",
    "    print('\\nResult keys:', list(result['result'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect extracted_values (what frontend receives)\n",
    "extracted_values = result.get('result', {}).get('extracted_values', [])\n",
    "print(f'Extracted values count: {len(extracted_values)}')\n",
    "\n",
    "if extracted_values:\n",
    "    print('\\nFirst extracted value structure:')\n",
    "    print(json.dumps(extracted_values[0], indent=2))\n",
    "    \n",
    "    print('\\n=== All Extracted Values ===')\n",
    "    for i, ev in enumerate(extracted_values, 1):\n",
    "        name = ev.get('field_name', '')\n",
    "        value = ev.get('value', '')\n",
    "        unit = ev.get('unit', '')\n",
    "        print(f'{i:2}. {name}: {value} {unit}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect universal_extraction (raw extraction data)\n",
    "universal = result.get('result', {}).get('universal_extraction', {})\n",
    "print('Universal extraction keys:', list(universal.keys()))\n",
    "\n",
    "test_results = universal.get('test_results', [])\n",
    "print(f'\\nTest results count: {len(test_results)}')\n",
    "\n",
    "if test_results:\n",
    "    print('\\nFirst test result structure:')\n",
    "    print(json.dumps(test_results[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check for CBC Differential in API Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for CBC differential in extracted_values\n",
    "cbc_keywords = ['wbc', 'rbc', 'hemoglobin', 'platelet', 'neutrophil', \n",
    "                'lymph', 'monocyte', 'eos', 'baso']\n",
    "\n",
    "cbc_in_extracted = [ev for ev in extracted_values \n",
    "                    if any(k in ev.get('field_name', '').lower() for k in cbc_keywords)]\n",
    "\n",
    "print(f'CBC tests in extracted_values: {len(cbc_in_extracted)}')\n",
    "for ev in cbc_in_extracted:\n",
    "    print(f\"  {ev.get('field_name')}: {ev.get('value')}\")\n",
    "\n",
    "# Check for basophils\n",
    "baso_extracted = [ev for ev in extracted_values if 'baso' in ev.get('field_name', '').lower()]\n",
    "if baso_extracted:\n",
    "    print(f'\\n✅ BASOPHILS in extracted_values:')\n",
    "    for b in baso_extracted:\n",
    "        print(f\"   {b.get('field_name')}: {b.get('value')}\")\n",
    "else:\n",
    "    print('\\n❌ Basophils NOT in extracted_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for CBC differential in universal_extraction.test_results\n",
    "cbc_in_universal = [t for t in test_results \n",
    "                    if any(k in t.get('name', '').lower() for k in cbc_keywords)]\n",
    "\n",
    "print(f'CBC tests in universal_extraction: {len(cbc_in_universal)}')\n",
    "for t in cbc_in_universal:\n",
    "    print(f\"  {t.get('name')}: {t.get('value')}\")\n",
    "\n",
    "# Check for basophils\n",
    "baso_universal = [t for t in test_results if 'baso' in t.get('name', '').lower()]\n",
    "if baso_universal:\n",
    "    print(f'\\n✅ BASOPHILS in universal_extraction:')\n",
    "    for b in baso_universal:\n",
    "        print(f\"   {b.get('name')}: {b.get('value')}\")\n",
    "else:\n",
    "    print('\\n❌ Basophils NOT in universal_extraction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare extracted_values vs universal_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare counts\n",
    "print(f'extracted_values count: {len(extracted_values)}')\n",
    "print(f'universal_extraction.test_results count: {len(test_results)}')\n",
    "\n",
    "# Find tests in universal but not in extracted\n",
    "extracted_names = {ev.get('field_name', '').lower() for ev in extracted_values}\n",
    "universal_names = {t.get('name', '').lower() for t in test_results}\n",
    "\n",
    "missing_from_extracted = universal_names - extracted_names\n",
    "print(f'\\nTests in universal but NOT in extracted_values ({len(missing_from_extracted)}):')\n",
    "for name in sorted(missing_from_extracted):\n",
    "    print(f'  - {name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Inspect Classification Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "classification = result.get('result', {}).get('classification', {})\nprint('Classification result:')\nprint(json.dumps(classification, indent=2))\n\nprint(f\"\\nDocument type: {result.get('result', {}).get('document_type')}\")"
  },
  {
   "cell_type": "code",
   "source": "# List all jobs (v2 endpoint)\nresponse = requests.get(f'{API_BASE}/api/v2/jobs')\njobs = response.json()\n\nprint(f'Total jobs: {len(jobs)}')\nfor job in jobs[-5:]:  # Show last 5\n    print(f\"  {job.get('job_id')[:8]}... - {job.get('status')} - {job.get('document_type', 'unknown')}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Get workflow steps for the job (v2 endpoint)\nresponse = requests.get(f'{API_BASE}/api/v2/jobs/{job_id}/workflow')\nworkflow = response.json()\n\nprint('Workflow steps:')\nfor step in workflow.get('steps', []):\n    status = step.get('status', 'unknown')\n    duration = step.get('duration_seconds', 0)\n    print(f\"  {step.get('name')}: {status} ({duration:.2f}s)\" if duration else f\"  {step.get('name')}: {status}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7b. Check Workflow Steps (v2 endpoint)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test with File Upload (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload a file directly\n",
    "file_path = '../data/samples/labs/labcorp/SampleLabCorpReport.pdf'\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    response = requests.post(\n",
    "        f'{API_BASE}/api/upload',\n",
    "        files={'file': f}\n",
    "    )\n",
    "\n",
    "upload_result = response.json()\n",
    "print('Upload result:')\n",
    "print(json.dumps(upload_result, indent=2))\n",
    "\n",
    "file_id = upload_result.get('file_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the uploaded file\n",
    "if file_id:\n",
    "    response = requests.post(\n",
    "        f'{API_BASE}/api/v2/process',\n",
    "        params={'file_id': file_id, 'strategy': 'router'}\n",
    "    )\n",
    "    \n",
    "    job_data = response.json()\n",
    "    print(f'Job ID: {job_data.get(\"job_id\")}')\n",
    "    \n",
    "    # Wait for completion\n",
    "    result = wait_for_job(job_data.get('job_id'))\n",
    "    \n",
    "    extracted_values = result.get('result', {}).get('extracted_values', [])\n",
    "    print(f'\\nExtracted values: {len(extracted_values)}')\n",
    "    \n",
    "    baso = [ev for ev in extracted_values if 'baso' in ev.get('field_name', '').lower()]\n",
    "    print(f'Basophils found: {\"YES\" if baso else \"NO\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Full Response for Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full API response to file for inspection\n",
    "with open('api_response_debug.json', 'w') as f:\n",
    "    json.dump(result, f, indent=2, default=str)\n",
    "\n",
    "print('Full API response saved to api_response_debug.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}