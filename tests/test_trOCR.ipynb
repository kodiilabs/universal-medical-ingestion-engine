{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "072e8b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TrOCR model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TrOCR Test - IMPORTANT: TrOCR is for SINGLE LINE text, not full documents!\n",
    "# =============================================================================\n",
    "# \n",
    "# TrOCR expects cropped text lines, not full document images.\n",
    "# For documents, you must:\n",
    "# 1. Detect text regions/lines first (using OpenCV or PaddleOCR detection)\n",
    "# 2. Crop each line\n",
    "# 3. OCR each cropped line with TrOCR\n",
    "#\n",
    "# This notebook demonstrates both the WRONG and RIGHT way to use TrOCR.\n",
    "# =============================================================================\n",
    "\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load TrOCR model\n",
    "print(\"Loading TrOCR model...\")\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "qoap91tr6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (852, 602)\n",
      "Passing ENTIRE document to TrOCR (WRONG!)...\n",
      "Result: '0 1'\n",
      "^ This fails because TrOCR expects SINGLE LINE text, not full documents!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ‚ùå WRONG WAY: Pass entire document to TrOCR (this will fail!)\n",
    "# =============================================================================\n",
    "\n",
    "path = \"../data/samples/prescriptions/ab36c7-20061128-oldprescrip.jpg\"\n",
    "image = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "print(f\"Image size: {image.size}\")\n",
    "print(\"Passing ENTIRE document to TrOCR (WRONG!)...\")\n",
    "\n",
    "pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "generated_ids = model.generate(pixel_values)\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "print(f\"Result: '{generated_text}'\")\n",
    "print(\"^ This fails because TrOCR expects SINGLE LINE text, not full documents!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "avmlb4cfisu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting text lines...\n",
      "Found 20 text lines\n",
      "\n",
      "OCR each line with TrOCR:\n",
      "--------------------------------------------------\n",
      "Line 1: '0 1'\n",
      "Line 2: '2 Primary Care Center .'\n",
      "Line 3: '6 Clinic 3A. Phillips-Wangensteen Building'\n",
      "Line 4: '516 Delaware Street Southeast . Minneapolis , MN 55455.'\n",
      "Line 5: 'Ritzen \" Mickey Mouse -'\n",
      "Line 6: 'assis relief #'\n",
      "Line 7: 'Address that has been'\n",
      "Line 8: 'Attendal 25mg.'\n",
      "Line 9: 'ago'\n",
      "Line 10: 'r.'\n",
      "Line 11: 'VOID'\n",
      "Line 12: 'Although it'\n",
      "Line 13: 'ii'\n",
      "Line 14: '\" ( ( see a refill phone numbers on tracks'\n",
      "Line 15: 'ex #'\n",
      "Line 16: 'exemptment'\n",
      "Line 17: 'threat #'\n",
      "Line 18: 'Health-administration Estimates .0000008'\n",
      "Line 19: 'staff physician disappointment by'\n",
      "Line 20: '166103. 3. 4.4'\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ‚úÖ RIGHT WAY: Detect text lines first, then OCR each line with TrOCR\n",
    "# =============================================================================\n",
    "\n",
    "def detect_text_lines(image_path):\n",
    "    \"\"\"\n",
    "    Detect text lines using OpenCV morphological operations.\n",
    "    Returns list of bounding boxes (x, y, w, h) for each text line.\n",
    "    \"\"\"\n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Binarize\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Dilate horizontally to connect text into lines\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 3))\n",
    "    dilated = cv2.dilate(binary, kernel, iterations=1)\n",
    "    \n",
    "    # Find contours (text lines)\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Get bounding boxes, filter by size, sort by y-position\n",
    "    boxes = []\n",
    "    for c in contours:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        # Filter: minimum width and height\n",
    "        if w > 50 and h > 10:\n",
    "            boxes.append((x, y, w, h))\n",
    "    \n",
    "    # Sort by y-position (top to bottom)\n",
    "    boxes.sort(key=lambda b: b[1])\n",
    "    \n",
    "    return boxes, img\n",
    "\n",
    "\n",
    "def ocr_with_trocr(image, boxes, processor, model):\n",
    "    \"\"\"\n",
    "    OCR each detected text line with TrOCR.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i, (x, y, w, h) in enumerate(boxes):\n",
    "        # Crop the text line with padding\n",
    "        pad = 5\n",
    "        y1 = max(0, y - pad)\n",
    "        y2 = min(image.shape[0], y + h + pad)\n",
    "        x1 = max(0, x - pad)\n",
    "        x2 = min(image.shape[1], x + w + pad)\n",
    "        \n",
    "        line_img = image[y1:y2, x1:x2]\n",
    "        \n",
    "        # Convert to PIL\n",
    "        pil_img = Image.fromarray(cv2.cvtColor(line_img, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # OCR with TrOCR\n",
    "        pixel_values = processor(pil_img, return_tensors=\"pt\").pixel_values\n",
    "        generated_ids = model.generate(pixel_values, max_length=64)\n",
    "        text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        \n",
    "        results.append({\n",
    "            'bbox': (x, y, w, h),\n",
    "            'text': text.strip()\n",
    "        })\n",
    "        \n",
    "        print(f\"Line {i+1}: '{text.strip()}'\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Run detection and OCR\n",
    "print(\"Detecting text lines...\")\n",
    "boxes, img = detect_text_lines(path)\n",
    "print(f\"Found {len(boxes)} text lines\\n\")\n",
    "\n",
    "print(\"OCR each line with TrOCR:\")\n",
    "print(\"-\" * 50)\n",
    "results = ocr_with_trocr(img, boxes, processor, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "qjn2xev8a5k",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Visualize detected text lines\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvisualize_detections\u001b[39m(image_path, boxes):\n\u001b[32m      7\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Draw bounding boxes on the image.\"\"\"\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Visualize detected text lines\n",
    "# =============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_detections(image_path, boxes):\n",
    "    \"\"\"Draw bounding boxes on the image.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    for i, (x, y, w, h) in enumerate(boxes):\n",
    "        cv2.rectangle(img_rgb, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        cv2.putText(img_rgb, str(i+1), (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title(f\"Detected {len(boxes)} text lines\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "visualize_detections(path, boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "io93un2nv5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üîë KEY INSIGHT: TrOCR vs PaddleOCR\n",
    "# =============================================================================\n",
    "#\n",
    "# | Model     | Detection | Recognition | Best For                        |\n",
    "# |-----------|-----------|-------------|----------------------------------|\n",
    "# | PaddleOCR | ‚úÖ Yes    | ‚úÖ Yes      | Clean printed text, fast         |\n",
    "# | TrOCR     | ‚ùå No     | ‚úÖ Yes      | Handwriting, degraded/noisy docs |\n",
    "#\n",
    "# For best results on prescriptions:\n",
    "# 1. Use PaddleOCR for text DETECTION (bounding boxes)\n",
    "# 2. Use TrOCR for text RECOGNITION (especially handwriting)\n",
    "#\n",
    "# This is what our ocr_router.py does:\n",
    "# - region_detector.py detects text regions\n",
    "# - ocr_router.py sends each region to TrOCR\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"‚ùå TrOCR on full document ‚Üí '0 1' (fails)\")\n",
    "print(\"‚úÖ TrOCR on detected lines ‚Üí works!\")\n",
    "print()\n",
    "print(\"The preprocessing pipeline handles this automatically:\")\n",
    "print(\"  1. document_pipeline.py preprocesses image\")\n",
    "print(\"  2. region_detector.py detects text regions\") \n",
    "print(\"  3. ocr_router.py sends each region to TrOCR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i7ygks3fts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ‚úÖ BEST WAY: Use the DocumentPipeline (production approach)\n",
    "# =============================================================================\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from src.medical_ingestion.core.document_pipeline import DocumentPipeline\n",
    "import asyncio\n",
    "\n",
    "async def process_with_pipeline(image_path):\n",
    "    \"\"\"Use the full document pipeline with region detection + TrOCR.\"\"\"\n",
    "    pipeline = DocumentPipeline({\n",
    "        'enable_preprocessing': True,\n",
    "        'enable_region_detection': True,\n",
    "        'use_vlm_classification': False,  # Don't need PaliGemma\n",
    "    })\n",
    "    \n",
    "    # Process the image\n",
    "    results = await pipeline.process_image(image_path)\n",
    "    \n",
    "    if results:\n",
    "        result = results[0]\n",
    "        print(f\"Full text extracted:\\n{result.full_text}\")\n",
    "        print(f\"\\nRegions detected: {result.total_regions}\")\n",
    "        print(f\"Average confidence: {result.average_confidence:.2f}\")\n",
    "        \n",
    "        if result.region_texts:\n",
    "            print(\"\\nText by region type:\")\n",
    "            for region_type, text in result.region_texts.items():\n",
    "                print(f\"  {region_type}: {text[:100]}...\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the pipeline\n",
    "# results = asyncio.run(process_with_pipeline(path))\n",
    "print(\"To use the full pipeline, run:\")\n",
    "print(\"  results = asyncio.run(process_with_pipeline(path))\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
